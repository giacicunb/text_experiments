{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentos XGBoost x SVM; TFIDF x Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fontes primárias:\n",
    "- Tutorial Using XGBoost in Python: https://www.datacamp.com/community/tutorials/xgboost-in-python\n",
    "- Documentação XGBoost Python API: https://xgboost.readthedocs.io/en/latest/python/python_api.html\n",
    "- XGBoost Python Package Introduction: https://xgboost-clone.readthedocs.io/en/latest/python/python_intro.html\n",
    "- Hyperparameter tuning in XGBoost: https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f\n",
    "- Linear SVC - Scikit Learn: https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn-svm-linearsvc\n",
    "- precision_recall_fscore_support - Scikit Learn: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "- TfidfVectorizer - Scikit Learn: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "- Embeddings NILC: http://www.nilc.icmc.usp.br/embeddings\n",
    "- Inferring the source of official texts: can SVM beat ULMFiT?: https://cic.unb.br/~teodecampos/KnEDLe/propor2020/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que este caderno se propôs a fazer\n",
    "Foram realizados testes com diferentes classificadores e representações textuais em um mesmo conjunto de dados, referente ao paper Inferring the source of official texts: can SVM beat ULMFiT?, disponível em https://cic.unb.br/~teodecampos/KnEDLe/propor2020/. As combinações estão listadas abaixo.\n",
    "\n",
    "- TFIDF + SVM\n",
    "- TFIDF + XGBoost\n",
    "- CBOW FastText 300D + SVM\n",
    "- SKIP-GRAM FastText 300D + SVM\n",
    "- SKIP-GRAM Word2Vec 300D + SVM\n",
    "- Glove 300D + SVM\n",
    "- CBOW FastText 300D + XGBoost\n",
    "- SKIP-GRAM FastText 300D + XGBoost\n",
    "- SKIP-GRAM Word2Vec 300D + XGBoost\n",
    "- Glove 300D + XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import do conjunto de dados:\n",
    " - Arquivo train.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                label  \\\n",
      "10  SECRETARIA DE ESTADO DE DESENVOLVIMENTO URBANO...   \n",
      "11  SECRETARIA DE ESTADO DE FAZENDA, PLANEJAMENTO,...   \n",
      "12                      SECRETARIA DE ESTADO DE SAÚDE   \n",
      "13          SECRETARIA DE ESTADO DE SEGURANÇA PÚBLICA   \n",
      "\n",
      "                                                 text  is_valid  \n",
      "10  O Termo de Recebimento Definitivo declarará fo...     False  \n",
      "11  O DISTRITO FEDERAL, por intermédio da Diretori...     False  \n",
      "12  O SECRETÁRIO DE ESTADO DE SAÚDE DO DISTRITO FE...     False  \n",
      "13  O DIRETOR-GERAL DO DEPARTAMENTO DE TRÂNSITO DO...     False  \n"
     ]
    }
   ],
   "source": [
    "path_to_text = '/home/mstauffer/Documentos/UnB/9º Semestre/KnEDle/sprints/5_27_maio-03_junho/luz_de_araujo_etal_propor2020/data/clean/train.csv'\n",
    "data_peter = pd.read_csv(path_to_text, encoding='utf8')#[['v1', 'v2']]\n",
    "# Creating the feature set and label set\n",
    "textPT = data_peter['text']\n",
    "labelPT = data_peter['label']\n",
    "print(data_peter[10:14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento para baseline\n",
    "- Processamos os dados de texto em representação TFIDF para usar como baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(717, 6000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = list(textPT)\n",
    "X_tfidf = TfidfVectorizer(max_features=6000) \n",
    "X_tfidf.fit(corpus)\n",
    "X_tfidf_features = X_tfidf.transform(corpus)\n",
    "print(X_tfidf_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pré-processamento do conjunto de labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15  6 15 11  0 13 10  2 14 18  8 11 14 15  4 18 15 15 10 10 10 12 11 11\n",
      " 15 15 11  6 14 15 11  0 16 11  1 18 15  8 13 10  6 15  6 15 16 10  8 12\n",
      " 11 15 15 13 16 15  3  5  3  6 11 15  0  2 15 15 11 15 16 14  5 15 14  2\n",
      " 18 14 11 14  3 12 16  6 16 15 13 12  2 15  6 13  0 13  0 12 18 14  9 16\n",
      " 14 14 15 11 15 15 13 15 13 15 14 13 18 11 14  7 15 18 16  6 10 16  0 11\n",
      "  6 16 10 17  0  8 15 15  6 11 10  8 16 11 10 15 10 14 16  0 15 15 14  3\n",
      " 11 14 11  0  3 15  7  7 14 12 18  2 13 13 18 18 10  0  0 15 14 16 18  5\n",
      " 14 11 16  8 11 15 15 16 18 11 14 11 16  3  6 10 15  0  0 14 10  6 15 15\n",
      " 10 15  0  0 14 13 14 15 15  2 16 13 15 10 12 16 11 11 13 11 14 15 15 10\n",
      "  4 14 14 14 15 14 13 14  0  1  0  9 10  2 10 16 13  3 11 15  6  0 15  3\n",
      " 13  0 10 11  0 15 15 11 15  3 15 15 15  3 18 15 16  6  1 16 16 14 15 14\n",
      " 13 14 18  6 15  3  3 14 13  0 16  0 15  5 13 15 15 16 14 18 15  0 13 14\n",
      " 15 13 15  0  0 11 14 15 13 15  0  0 15 15  8 15 15 11 14  6 15 14 14  0\n",
      " 16  2  6  2 17 13  7  2 15 16  3 14 13 16 15  2  0 13 15 16 15  0 15 11\n",
      "  6 18 14 18  7  3 10  6 10 15 11 14 16  0 16 15 11 10 15  6 13  2 13  8\n",
      " 16 16 14 16  3 15 14 15 11 10 14 16  4 16  6 13  0 15 11 13 14 15 15 18\n",
      " 15 16 15 14 13 14 11  6  3  3 16 13 12 18 14  6 14 18 13 15 13  2 14 14\n",
      " 15 16  7 11 14 10  1  3  6 15  0 14 15 14 12 11  2  0 15  3  5 10  5 11\n",
      " 11  2  0 14 15  9 15 18  0 14 15 15  6  6  6 16 17 14 15 15 13  3 14 15\n",
      " 14 11 13 13 10  3 15 14  7  0 15 14 13 14 14  0 16 15 14 11 14 15  5 15\n",
      "  0 15 16 14 15 15 14 14 15 18 14 15 14 15 18 14 14 14 15 14  0  6  4  8\n",
      "  0 13 15  0 11  6  6 16 15 15 11 16 18 14 15 13  6 10 15 15 15  5 13 15\n",
      "  2  2 11 10  8 16 14 11  6 15 15 15 14  0  3 14  2 11 10 16  3 12  5  5\n",
      " 16 10 17 15 13  7  2  0  2 10 16 10  5 12  0 11 12 13  7 15 16 15  2 15\n",
      "  6  6 11  0 11 17  3  0 13  0 14 14 13 13  0  1 10  6 15  0 11  7 15  3\n",
      " 16 13 15 11  2  3 15 10  0 16  6 13 14 18 16 11 18 15 11 11  6 14  6 10\n",
      " 10 18  9 16 11 16 16 15 11 14 13  0 16 14 12  6 15  0 14 14 15 16 13 13\n",
      " 10 15  0  1 15 14  3 15 16 15 15  3  8 14 16 14  0 10 15 12 18 11 13 14\n",
      " 15 13 11 11  6 13 15 18 14 18  3 15 15 11 15 18 15 18 14 15 15 13 15 15\n",
      " 14  0 11 15 16 16 14 14  3 10 11  2  8  3 15 14 13  7 15 15 14]\n",
      "(717,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "# Converting the labels from strings to binary\n",
    "le = LabelEncoder()\n",
    "le.fit(labelPT)\n",
    "y_labelPT = le.transform(labelPT)\n",
    "print(y_labelPT)\n",
    "print(y_labelPT.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split em treino e teste - baseline\n",
    "- OBS: Os labels também serão utilizados com outras representações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5865)\t0.12310278357902607\n",
      "  (0, 5844)\t0.07214349812284936\n",
      "  (0, 5835)\t0.0868076648446096\n",
      "  (0, 5754)\t0.041587122710311904\n",
      "  (0, 5743)\t0.10162001575332077\n",
      "  (0, 5668)\t0.028382729835351277\n",
      "  (0, 5420)\t0.2645848762644777\n",
      "  (0, 5401)\t0.05307699402489731\n",
      "  (0, 5400)\t0.04830196249802336\n",
      "  (0, 5385)\t0.07645466551500592\n",
      "  (0, 5356)\t0.09638715650117681\n",
      "  (0, 5349)\t0.05393150042329729\n",
      "  (0, 5331)\t0.0282035262524768\n",
      "  (0, 5270)\t0.2223558217390038\n",
      "  (0, 5251)\t0.07931376976638826\n",
      "  (0, 5130)\t0.05583318328674835\n",
      "  (0, 5018)\t0.09662967176577104\n",
      "  (0, 4963)\t0.052275930237077724\n",
      "  (0, 4957)\t0.09193180845870408\n",
      "  (0, 4956)\t0.06077461776690305\n",
      "  (0, 4929)\t0.2379413092991648\n",
      "  (0, 4863)\t0.1494332956490792\n",
      "  (0, 4832)\t0.05635622926945937\n",
      "  (0, 4831)\t0.05128648248887804\n",
      "  (0, 4790)\t0.06575128557963889\n",
      "  :\t:\n",
      "  (572, 855)\t0.10020939169551783\n",
      "  (572, 754)\t0.09235404367340458\n",
      "  (572, 615)\t0.09712011448381817\n",
      "  (572, 575)\t0.13776221649461948\n",
      "  (572, 537)\t0.08245792432452834\n",
      "  (572, 517)\t0.07229381086033336\n",
      "  (572, 515)\t0.15853010198422748\n",
      "  (572, 481)\t0.13506393854104018\n",
      "  (572, 433)\t0.11373317426261102\n",
      "  (572, 382)\t0.09661366306674751\n",
      "  (572, 292)\t0.06554073117806167\n",
      "  (572, 288)\t0.11373317426261102\n",
      "  (572, 261)\t0.05965699189181787\n",
      "  (572, 231)\t0.05758637342082007\n",
      "  (572, 215)\t0.04401163842917111\n",
      "  (572, 203)\t0.060201905086114366\n",
      "  (572, 188)\t0.07100227902156034\n",
      "  (572, 175)\t0.06822017135665062\n",
      "  (572, 111)\t0.06132779865219117\n",
      "  (572, 109)\t0.11059333444032186\n",
      "  (572, 34)\t0.09956100379906122\n",
      "  (572, 9)\t0.12467999579623618\n",
      "  (572, 6)\t0.07509039969834287\n",
      "  (572, 1)\t0.07365395104063086\n",
      "  (572, 0)\t0.06438021109007944\n",
      "  (0, 5957)\t0.0066308016290965895\n",
      "  (0, 5951)\t0.016085669732165995\n",
      "  (0, 5939)\t0.007716348130756908\n",
      "  (0, 5897)\t0.08324125375626923\n",
      "  (0, 5891)\t0.01060831151756678\n",
      "  (0, 5835)\t0.07269341132737506\n",
      "  (0, 5831)\t0.01895581981127098\n",
      "  (0, 5768)\t0.009056995296660885\n",
      "  (0, 5713)\t0.10203024654662098\n",
      "  (0, 5705)\t0.009056995296660885\n",
      "  (0, 5679)\t0.1638909589785536\n",
      "  (0, 5619)\t0.17315108037599486\n",
      "  (0, 5611)\t0.008042834866082997\n",
      "  (0, 5585)\t0.00733247661993917\n",
      "  (0, 5510)\t0.16131448563866174\n",
      "  (0, 5451)\t0.0075768974979046975\n",
      "  (0, 5440)\t0.00327583489762761\n",
      "  (0, 5435)\t0.11051469829213909\n",
      "  (0, 5396)\t0.13036787834807453\n",
      "  (0, 5363)\t0.05686745943381294\n",
      "  (0, 5356)\t0.08071535188463497\n",
      "  (0, 5338)\t0.13600626550649816\n",
      "  (0, 5327)\t0.19235204331244554\n",
      "  (0, 5245)\t0.00887582301147647\n",
      "  (0, 5220)\t0.011164426315516717\n",
      "  :\t:\n",
      "  (143, 1403)\t0.13335585936325944\n",
      "  (143, 1286)\t0.07575292398768245\n",
      "  (143, 1273)\t0.12672387792716236\n",
      "  (143, 1248)\t0.07878617508618571\n",
      "  (143, 1188)\t0.13335585936325944\n",
      "  (143, 1177)\t0.10934705441567469\n",
      "  (143, 1164)\t0.2120160166924714\n",
      "  (143, 1081)\t0.05494750494810475\n",
      "  (143, 974)\t0.11737662508293388\n",
      "  (143, 970)\t0.13335585936325944\n",
      "  (143, 827)\t0.07807679105228824\n",
      "  (143, 732)\t0.07017083012918868\n",
      "  (143, 623)\t0.056401194375342294\n",
      "  (143, 594)\t0.07482448326433208\n",
      "  (143, 505)\t0.05884524898400654\n",
      "  (143, 461)\t0.06192356981739966\n",
      "  (143, 420)\t0.04793447083549635\n",
      "  (143, 398)\t0.10802937223870543\n",
      "  (143, 382)\t0.028989384831494446\n",
      "  (143, 381)\t0.0537010845343825\n",
      "  (143, 375)\t0.0534596879616317\n",
      "  (143, 359)\t0.051949369107043716\n",
      "  (143, 215)\t0.03961769845967966\n",
      "  (143, 198)\t0.08962124491688721\n",
      "  (143, 86)\t0.042866014703680996\n",
      "[ 9  7  3  0  0  0 16 14 13 15  0  6 11 18  6  0 15 14  6 15  4 15 15  6\n",
      " 18 11 16 15 10  6 13 14 15 13 14 16  0 13 10 14 17  2 14 15 15 15 15  0\n",
      " 15 15 15 13 15  2 16 18 15 13 11 15 14  2 18  0 10 15 14  6 13  5 15 14\n",
      " 10 16 10 13 15 15 15 11  8  0 15  1 11 15 14  0  0 18  6  6 13 14  8 15\n",
      " 15  0 15 16 15 14 15 15 14  5  6  5 15  0 12 10 18  8  3 15 10 15 11 14\n",
      " 15 18 14  2 15 14  6 17 16 13 11 15  7 15 10 14  3 16 15 15 13 14 14 14\n",
      "  5 14 10  3 15 15 15 14 16 11  6 13 15 11  8 15 11  2 13 16 16 10  6 11\n",
      "  0 11 14 15 14 16 15  8 16 10  6 15 14 16 11 10 16  0 14  5 14 15 16 16\n",
      " 15 15 14 11  0 14 10 15 16  6  2 18 13  6 14  4 15  6  3 13 14 14 15  5\n",
      " 13 12 11 13 11  3 11 14 14  3 14  6 15 10  6 14 14 18 12 18  1 15 16 15\n",
      "  1  9 18 13 12 13  0 11 10 14 15 16  0  0  6 13 10 17 13  3 14 18 14 15\n",
      " 15  8  2  6  3 15 16 16  2 15 13 14 14  0 14 14 13 11 10 10 10 11 14 15\n",
      " 14 15 15 16 11  6  2 10 15 15  6  0  6 18  2 16 12 10  0 15 15 15 13 15\n",
      " 15 15 16 11 15  3  3 11 15 14 14  2 11 16 15  0 16 14  3 15  2 15  7 15\n",
      "  3 15 14 15 13 16 16  7  7 11 15  9 14 11  0  2 18 18 14 18 14 14 10 16\n",
      " 15 14 13  2 13  5 15 13 13 14 14 12 15  1 14 13  6  3 10 10 10 15  1  6\n",
      " 13 11 13  8 15 15 16  3 15  0  0 15 16 16 11  4  3 15  0 14 16 14 14 15\n",
      " 13 18  7 16  8 11 13  7 10  0 16 13 10  3 14  6 15  0  0 13  6  5 18 14\n",
      " 14 10  3 16 10 11 15 15 12 14 12 15 11 16  2 15  0 14 15  2  3 14 15  0\n",
      " 14 16  0 14 16 14  2 15  0 13  2 10  8  6 11 16 15 15 15 14 18 15 15 15\n",
      " 14 14  4 13 14 15 13 16 11 15 18 11 15  0 14 16 10  3 15 13 15  0 11 11\n",
      "  0 15  2  0 15 11  8  0 15 11 18 16 15  3 15 18 11 14 15 11 16  0  6  3\n",
      " 13 15 11 16 15 13 16 14 11 15 18  0  0 11  7 10  7 15 15  5 11  0 15  3\n",
      " 18 16  7  0  2 14 12 12 18 14 15 13 17 14  0 15 15  3 15 15  6]\n",
      "[14 14 14  0  6  3  6 14  0 16 10 15  0  0 16 15 10  6 15  8 15 13 14  0\n",
      " 15 11 15 12 18 11 15 11  0 10 11  3 15 16 15 12 15 13 11  6 13  6 16 15\n",
      "  3 15 15 14  2  2 14 14 11 13 10 14 16 11  6  6 13  9 15 14 12  6  3 13\n",
      " 16 11 12 11 13 13 15 18 10 18  6  3  6 15 14 11 11 14  2 15 16 16 18  5\n",
      "  5 14 15 10 13 11 13 14 18  1  0 11 11 17 16 13  0 10 13 14 13 11  3  7\n",
      " 16 18 18  0 10  8 15 16 14 11 15 15 15 11  0 11 11  0 15 15 15  3 14 16]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_features, y_labelPT, test_size=0.2, random_state=123)\n",
    "print(X_train)\n",
    "print(X_test)\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline SVM + TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_modelPT = LinearSVC(max_iter=1000)\n",
    "svm_modelPT.fit(X_train, y_train)\n",
    "svm_predictionPT = svm_modelPT.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciação de objeto XGBClassifier\n",
    "Instanciação e fit do objeto com X e y de treino. Call do método predict e store em variável para análise de perfomance.\n",
    "\n",
    "Refs: \n",
    "- https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier\n",
    "- https://info.cambridgespark.com/latest/getting-started-with-xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_cls = xgb.XGBClassifier(base_score=0.5, colsample_bylevel=1, objective='multi:softprob', colsample_bytree = 1, gamma=0, learning_rate = 0.1, max_delta_step=0,\n",
    "                max_depth = 3, min_child_weight=1, missing=None, alpha = 10, n_estimators = 100, nthread=-1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:35:26] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=-1, nthread=-1, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=42, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, seed=42, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_cls.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 14 14  0  6 16  6 14  0 15 10 15  0  0 16 15 10  6 15  8 15 13 14  0\n",
      " 15 11 15 12 18 15 15 11  0 10 11  3 15 16 15 12 15 13 11  6 13  6 16 15\n",
      "  3 15 15 14  2  2 14 14 13 13 10 14 16 11  6  6 13  9 15 14 16  6  3 10\n",
      " 16 11 12 11 13 13 15 18 10 18  6  3  6 15 14 11 11 14  2 15 16 11 18  5\n",
      "  5 14 15 10 13 11 13 14 18  1  0 13 11 13 16 13  0 10 13 14 13 11  3  7\n",
      " 15 18 18  0 10  8 15 16 14 11 15 15 15 11  0 11 11  0 15 15 15  3 14 16]\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos baseados em Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import de embeddings\n",
    "\n",
    "Foram conduzidos testes com diferentes conjuntos de vetores pré-treinados em língua portuguesa. Os arquivos usados estão disponíveis em http://www.nilc.icmc.usp.br/embeddings. A saber, são eles:\n",
    "- FastText CBOW 300 dimensões\n",
    "- FastText SKIP-GRAM 300 dimensões\n",
    "- Word2Vec SKIP-GRAM 300 dimensões\n",
    "- Glove 300 dimensões\n",
    "\n",
    "A fim de preservar memória, apenas as 100000 palavras mais frequentes foram usadas. Além disso, as duas células abaixo foram executadas sobrescrevendo as variáveis envolvidas a cada mudança de conjunto de embeddings. Apenas uma linha era modificada (path_emb = 'modelo'). Carregadas as informações do modelo, os testes seguiam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.457517, -0.08992, 0.344763, 0.041031, 0.072887, -0.974737, 0.160377, -0.719449, -0.217797, 0.267011, -0.652553, 0.331003, 0.089468, -0.116183, 0.74115, -0.242831, -0.525771, 0.168315, -0.480077, 0.419809, 0.099425, -0.494544, 0.697174, 0.14046, -0.31801, -0.249461, -0.979818, -0.400552, -0.114748, 0.189945, 0.367923, -0.060311, -0.320324, -0.68412, -0.429739, -0.151582, 0.007587, 0.710586, -0.251371, 0.561936, -0.402018, -0.443148, -0.1371, -0.400934, -0.470808, -0.318996, -0.451779, -0.220812, 0.893261, 0.561035, -0.215192, -0.376958, 0.099948, 0.247093, -0.459781, 0.470335, 0.68523, 0.58447, -0.273652, -0.506633, -0.006587, 0.459712, 0.005831, 0.173205, -0.295872, -0.220857, 0.161053, -0.484545, 0.114365, 0.381987, -0.29784, -0.511537, 0.324228, 0.200679, 0.109674, -0.0143, -0.144205, -0.395351, 0.105982, 0.283204, 0.04553, -0.007537, 0.983664, -0.276508, 0.625008, -0.170508, 0.34148, -0.216058, -0.120424, -0.014769, 0.765968, -0.129805, 0.596335, 0.431591, -0.114619, 0.118298, 0.344341, -0.269631, 0.147996, -0.276276, -0.372461, -0.592851, 0.134765, 0.033997, 3.13984, -0.321225, 0.274189, 0.180978, 0.239061, -0.307632, 0.172832, 0.09271, -0.282524, 0.125826, -0.321968, 0.215544, -0.577293, -0.174814, -0.060613, 0.091196, -0.109775, 0.220184, 0.366019, 0.211454, -1.077585, 0.265718, 0.449351, 0.458496, -0.036151, -0.603453, -0.367024, 0.238417, -0.772772, 0.30163, -0.266241, 0.036174, -0.142246, -0.183127, 0.775846, 0.021013, 0.038602, 0.183731, -0.601901, -0.626276, -0.086273, -0.559756, 0.05009, 0.10416, -0.444438, -0.480229, 0.120853, -0.284383, -0.091654, -0.36188, 0.03407, -0.137851, 0.471704, -0.3211, -0.37607, -0.372286, -0.498542, 0.882514, 0.205247, -0.249697, -0.179061, 1.151474, -0.070372, 0.170966, 0.110853, 0.050513, 0.65023, 0.050564, -0.108261, 0.246673, 0.632009, 0.622247, -0.249277, 0.062997, -0.163947, -0.150027, 0.159381, 0.333317, 0.077062, 0.353603, 0.07185, -0.216823, 0.130514, -0.277562, 0.141324, 0.076124, -0.39066, 0.553653, -0.159852, -0.533546, -0.434329, 0.216262, -0.414249, 0.25898, -0.531573, -0.224392, 0.897213, -0.355496, 0.473419, -0.019158, 0.237966, 0.05125, 0.059345, 0.028693, 0.734427, 0.835811, 0.088655, -0.413746, -0.602852, 0.313857, 0.960704, 0.510168, 0.172447, -0.116558, 0.547286, 0.483142, 0.589382, -0.67909, 0.025105, 0.345979, -0.969901, 0.575132, -0.644327, 0.097144, 0.057302, 0.110299, 0.683917, -0.073654, -0.335089, -0.031675, -0.173525, 0.096014, -0.464959, -0.318228, -0.151131, -0.575971, 0.206059, -0.179247, 0.147324, -0.191954, -0.654552, -0.130959, -0.238959, 0.104235, 0.316329, -0.05291, -0.194832, -0.136348, 0.385625, 0.141737, -1.028391, -0.231693, -0.110786, 0.079556, -0.341463, -0.202203, 0.530326, -0.54519, -0.612679, 0.258121, 0.00675, -0.329613, 0.154835, -0.490387, 0.058212, 0.182172, 0.458361, 1.071762, -0.098516, 0.231545, 0.17867, -0.092196, 0.047702, -0.582918, 0.309364, -0.683072, 0.018406, -0.296958, 0.18503, 0.303023, 0.123339, 0.139122, 0.081098, 0.709496, -0.553765, -0.251709, 0.073034, 0.063336, 0.296621, 0.184657, -0.102374, -0.032529, 0.26575, 0.151103, 0.331813, -0.082634]\n"
     ]
    }
   ],
   "source": [
    "# Loading the data file from local download\n",
    "path_emb = 'glove_s300.txt'\n",
    "dictionary = open(path_emb, 'r', encoding='utf-8',\n",
    "                  newline='\\n', errors='ignore')\n",
    "embedsPT = {}\n",
    "for line in dictionary:\n",
    "    tokens = line.rstrip().split(' ')\n",
    "    embedsPT[tokens[0]] = [float(x) for x in tokens[1:]]\n",
    "    \n",
    "    if len(embedsPT) == 100000:\n",
    "        break\n",
    "print(embedsPT['carro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteração 1\n",
      "Zeros_to_add: 300\n",
      "Iteração 2\n",
      "Zeros_to_add: 2100\n",
      "Iteração 3\n",
      "Zeros_to_add: 300\n",
      "Iteração 4\n",
      "Zeros_to_add: 600\n",
      "Iteração 5\n",
      "Zeros_to_add: 300\n",
      "Iteração 6\n",
      "Zeros_to_add: 1500\n",
      "Iteração 7\n",
      "Zeros_to_add: 300\n",
      "Iteração 8\n",
      "Zeros_to_add: 0\n",
      "Iteração 9\n",
      "Zeros_to_add: 300\n",
      "Iteração 10\n",
      "Zeros_to_add: 0\n",
      "Iteração 11\n",
      "Zeros_to_add: 600\n",
      "Iteração 12\n",
      "Zeros_to_add: 0\n",
      "Iteração 13\n",
      "Zeros_to_add: 300\n",
      "Iteração 14\n",
      "Zeros_to_add: 300\n",
      "Iteração 15\n",
      "Zeros_to_add: 1200\n",
      "Iteração 16\n",
      "Zeros_to_add: 0\n",
      "Iteração 17\n",
      "Zeros_to_add: 1500\n",
      "Iteração 18\n",
      "Zeros_to_add: 900\n",
      "Iteração 19\n",
      "Zeros_to_add: 0\n",
      "Iteração 20\n",
      "Zeros_to_add: 0\n",
      "Iteração 21\n",
      "Zeros_to_add: 0\n",
      "Iteração 22\n",
      "Zeros_to_add: 0\n",
      "Iteração 23\n",
      "Zeros_to_add: 0\n",
      "Iteração 24\n",
      "Zeros_to_add: 0\n",
      "Iteração 25\n",
      "Zeros_to_add: 1200\n",
      "Iteração 26\n",
      "Zeros_to_add: 2700\n",
      "Iteração 27\n",
      "Zeros_to_add: 900\n",
      "Iteração 28\n",
      "Zeros_to_add: 2700\n",
      "Iteração 29\n",
      "Zeros_to_add: 300\n",
      "Iteração 30\n",
      "Zeros_to_add: 300\n",
      "Iteração 31\n",
      "Zeros_to_add: 900\n",
      "Iteração 32\n",
      "Zeros_to_add: 0\n",
      "Iteração 33\n",
      "Zeros_to_add: 0\n",
      "Iteração 34\n",
      "Zeros_to_add: 0\n",
      "Iteração 35\n",
      "Zeros_to_add: 300\n",
      "Iteração 36\n",
      "Zeros_to_add: 0\n",
      "Iteração 37\n",
      "Zeros_to_add: 300\n",
      "Iteração 38\n",
      "Zeros_to_add: 900\n",
      "Iteração 39\n",
      "Zeros_to_add: 3000\n",
      "Iteração 40\n",
      "Zeros_to_add: 1500\n",
      "Iteração 41\n",
      "Zeros_to_add: 1800\n",
      "Iteração 42\n",
      "Zeros_to_add: 300\n",
      "Iteração 43\n",
      "Zeros_to_add: 2100\n",
      "Iteração 44\n",
      "Zeros_to_add: 300\n",
      "Iteração 45\n",
      "Zeros_to_add: 1200\n",
      "Iteração 46\n",
      "Zeros_to_add: 2700\n",
      "Iteração 47\n",
      "Zeros_to_add: 300\n",
      "Iteração 48\n",
      "Zeros_to_add: 0\n",
      "Iteração 49\n",
      "Zeros_to_add: 600\n",
      "Iteração 50\n",
      "Zeros_to_add: 0\n",
      "Iteração 51\n",
      "Zeros_to_add: 300\n",
      "Iteração 52\n",
      "Zeros_to_add: 2100\n",
      "Iteração 53\n",
      "Zeros_to_add: 0\n",
      "Iteração 54\n",
      "Zeros_to_add: 300\n",
      "Iteração 55\n",
      "Zeros_to_add: 300\n",
      "Iteração 56\n",
      "Zeros_to_add: 300\n",
      "Iteração 57\n",
      "Zeros_to_add: 1500\n",
      "Iteração 58\n",
      "Zeros_to_add: 2100\n",
      "Iteração 59\n",
      "Zeros_to_add: 0\n",
      "Iteração 60\n",
      "Zeros_to_add: 1500\n",
      "Iteração 61\n",
      "Zeros_to_add: 1500\n",
      "Iteração 62\n",
      "Zeros_to_add: 0\n",
      "Iteração 63\n",
      "Zeros_to_add: 0\n",
      "Iteração 64\n",
      "Zeros_to_add: 1800\n",
      "Iteração 65\n",
      "Zeros_to_add: 900\n",
      "Iteração 66\n",
      "Zeros_to_add: 2100\n",
      "Iteração 67\n",
      "Zeros_to_add: 300\n",
      "Iteração 68\n",
      "Zeros_to_add: 1200\n",
      "Iteração 69\n",
      "Zeros_to_add: 300\n",
      "Iteração 70\n",
      "Zeros_to_add: 2400\n",
      "Iteração 71\n",
      "Zeros_to_add: 300\n",
      "Iteração 72\n",
      "Zeros_to_add: 1200\n",
      "Iteração 73\n",
      "Zeros_to_add: 0\n",
      "Iteração 74\n",
      "Zeros_to_add: 0\n",
      "Iteração 75\n",
      "Zeros_to_add: 300\n",
      "Iteração 76\n",
      "Zeros_to_add: 0\n",
      "Iteração 77\n",
      "Zeros_to_add: 300\n",
      "Iteração 78\n",
      "Zeros_to_add: 1200\n",
      "Iteração 79\n",
      "Zeros_to_add: 0\n",
      "Iteração 80\n",
      "Zeros_to_add: 2700\n",
      "Iteração 81\n",
      "Zeros_to_add: 1200\n",
      "Iteração 82\n",
      "Zeros_to_add: 900\n",
      "Iteração 83\n",
      "Zeros_to_add: 0\n",
      "Iteração 84\n",
      "Zeros_to_add: 0\n",
      "Iteração 85\n",
      "Zeros_to_add: 0\n",
      "Iteração 86\n",
      "Zeros_to_add: 900\n",
      "Iteração 87\n",
      "Zeros_to_add: 2700\n",
      "Iteração 88\n",
      "Zeros_to_add: 1200\n",
      "Iteração 89\n",
      "Zeros_to_add: 0\n",
      "Iteração 90\n",
      "Zeros_to_add: 1800\n",
      "Iteração 91\n",
      "Zeros_to_add: 300\n",
      "Iteração 92\n",
      "Zeros_to_add: 1500\n",
      "Iteração 93\n",
      "Zeros_to_add: 1200\n",
      "Iteração 94\n",
      "Zeros_to_add: 300\n",
      "Iteração 95\n",
      "Zeros_to_add: 600\n",
      "Iteração 96\n",
      "Zeros_to_add: 1200\n",
      "Iteração 97\n",
      "Zeros_to_add: 600\n",
      "Iteração 98\n",
      "Zeros_to_add: 0\n",
      "Iteração 99\n",
      "Zeros_to_add: 300\n",
      "Iteração 100\n",
      "Zeros_to_add: 0\n",
      "Iteração 101\n",
      "Zeros_to_add: 300\n",
      "Iteração 102\n",
      "Zeros_to_add: 300\n",
      "Iteração 103\n",
      "Zeros_to_add: 3300\n",
      "Iteração 104\n",
      "Zeros_to_add: 300\n",
      "Iteração 105\n",
      "Zeros_to_add: 0\n",
      "Iteração 106\n",
      "Zeros_to_add: 1800\n",
      "Iteração 107\n",
      "Zeros_to_add: 0\n",
      "Iteração 108\n",
      "Zeros_to_add: 0\n",
      "Iteração 109\n",
      "Zeros_to_add: 900\n",
      "Iteração 110\n",
      "Zeros_to_add: 600\n",
      "Iteração 111\n",
      "Zeros_to_add: 2700\n",
      "Iteração 112\n",
      "Zeros_to_add: 600\n",
      "Iteração 113\n",
      "Zeros_to_add: 300\n",
      "Iteração 114\n",
      "Zeros_to_add: 0\n",
      "Iteração 115\n",
      "Zeros_to_add: 0\n",
      "Iteração 116\n",
      "Zeros_to_add: 1800\n",
      "Iteração 117\n",
      "Zeros_to_add: 0\n",
      "Iteração 118\n",
      "Zeros_to_add: 1200\n",
      "Iteração 119\n",
      "Zeros_to_add: 0\n",
      "Iteração 120\n",
      "Zeros_to_add: 0\n",
      "Iteração 121\n",
      "Zeros_to_add: 2700\n",
      "Iteração 122\n",
      "Zeros_to_add: 300\n",
      "Iteração 123\n",
      "Zeros_to_add: 0\n",
      "Iteração 124\n",
      "Zeros_to_add: 0\n",
      "Iteração 125\n",
      "Zeros_to_add: 1200\n",
      "Iteração 126\n",
      "Zeros_to_add: 900\n",
      "Iteração 127\n",
      "Zeros_to_add: 300\n",
      "Iteração 128\n",
      "Zeros_to_add: 1200\n",
      "Iteração 129\n",
      "Zeros_to_add: 2100\n",
      "Iteração 130\n",
      "Zeros_to_add: 0\n",
      "Iteração 131\n",
      "Zeros_to_add: 0\n",
      "Iteração 132\n",
      "Zeros_to_add: 0\n",
      "Iteração 133\n",
      "Zeros_to_add: 0\n",
      "Iteração 134\n",
      "Zeros_to_add: 1200\n",
      "Iteração 135\n",
      "Zeros_to_add: 0\n",
      "Iteração 136\n",
      "Zeros_to_add: 0\n",
      "Iteração 137\n",
      "Zeros_to_add: 0\n",
      "Iteração 138\n",
      "Zeros_to_add: 0\n",
      "Iteração 139\n",
      "Zeros_to_add: 0\n",
      "Iteração 140\n",
      "Zeros_to_add: 300\n",
      "Iteração 141\n",
      "Zeros_to_add: 1500\n",
      "Iteração 142\n",
      "Zeros_to_add: 300\n",
      "Iteração 143\n",
      "Zeros_to_add: 600\n",
      "Iteração 144\n",
      "Zeros_to_add: 300\n",
      "Iteração 145\n",
      "Zeros_to_add: 1200\n",
      "Iteração 146\n",
      "Zeros_to_add: 0\n",
      "Iteração 147\n",
      "Zeros_to_add: 300\n",
      "Iteração 148\n",
      "Zeros_to_add: 0\n",
      "Iteração 149\n",
      "Zeros_to_add: 1800\n",
      "Iteração 150\n",
      "Zeros_to_add: 300\n",
      "Iteração 151\n",
      "Zeros_to_add: 1500\n",
      "Iteração 152\n",
      "Zeros_to_add: 300\n",
      "Iteração 153\n",
      "Zeros_to_add: 2100\n",
      "Iteração 154\n",
      "Zeros_to_add: 0\n",
      "Iteração 155\n",
      "Zeros_to_add: 0\n",
      "Iteração 156\n",
      "Zeros_to_add: 0\n",
      "Iteração 157\n",
      "Zeros_to_add: 300\n",
      "Iteração 158\n",
      "Zeros_to_add: 0\n",
      "Iteração 159\n",
      "Zeros_to_add: 0\n",
      "Iteração 160\n",
      "Zeros_to_add: 0\n",
      "Iteração 161\n",
      "Zeros_to_add: 0\n",
      "Iteração 162\n",
      "Zeros_to_add: 300\n",
      "Iteração 163\n",
      "Zeros_to_add: 0\n",
      "Iteração 164\n",
      "Zeros_to_add: 1500\n",
      "Iteração 165\n",
      "Zeros_to_add: 300\n",
      "Iteração 166\n",
      "Zeros_to_add: 0\n",
      "Iteração 167\n",
      "Zeros_to_add: 0\n",
      "Iteração 168\n",
      "Zeros_to_add: 300\n",
      "Iteração 169\n",
      "Zeros_to_add: 0\n",
      "Iteração 170\n",
      "Zeros_to_add: 0\n",
      "Iteração 171\n",
      "Zeros_to_add: 300\n",
      "Iteração 172\n",
      "Zeros_to_add: 0\n",
      "Iteração 173\n",
      "Zeros_to_add: 0\n",
      "Iteração 174\n",
      "Zeros_to_add: 300\n",
      "Iteração 175\n",
      "Zeros_to_add: 300\n",
      "Iteração 176\n",
      "Zeros_to_add: 0\n",
      "Iteração 177\n",
      "Zeros_to_add: 0\n",
      "Iteração 178\n",
      "Zeros_to_add: 0\n",
      "Iteração 179\n",
      "Zeros_to_add: 0\n",
      "Iteração 180\n",
      "Zeros_to_add: 0\n",
      "Iteração 181\n",
      "Zeros_to_add: 0\n",
      "Iteração 182\n",
      "Zeros_to_add: 300\n",
      "Iteração 183\n",
      "Zeros_to_add: 2700\n",
      "Iteração 184\n",
      "Zeros_to_add: 0\n",
      "Iteração 185\n",
      "Zeros_to_add: 900\n",
      "Iteração 186\n",
      "Zeros_to_add: 300\n",
      "Iteração 187\n",
      "Zeros_to_add: 0\n",
      "Iteração 188\n",
      "Zeros_to_add: 0\n",
      "Iteração 189\n",
      "Zeros_to_add: 300\n",
      "Iteração 190\n",
      "Zeros_to_add: 2700\n",
      "Iteração 191\n",
      "Zeros_to_add: 900\n",
      "Iteração 192\n",
      "Zeros_to_add: 300\n",
      "Iteração 193\n",
      "Zeros_to_add: 0\n",
      "Iteração 194\n",
      "Zeros_to_add: 0\n",
      "Iteração 195\n",
      "Zeros_to_add: 0\n",
      "Iteração 196\n",
      "Zeros_to_add: 0\n",
      "Iteração 197\n",
      "Zeros_to_add: 300\n",
      "Iteração 198\n",
      "Zeros_to_add: 3000\n",
      "Iteração 199\n",
      "Zeros_to_add: 600\n",
      "Iteração 200\n",
      "Zeros_to_add: 0\n",
      "Iteração 201\n",
      "Zeros_to_add: 600\n",
      "Iteração 202\n",
      "Zeros_to_add: 0\n",
      "Iteração 203\n",
      "Zeros_to_add: 900\n",
      "Iteração 204\n",
      "Zeros_to_add: 600\n",
      "Iteração 205\n",
      "Zeros_to_add: 0\n",
      "Iteração 206\n",
      "Zeros_to_add: 2400\n",
      "Iteração 207\n",
      "Zeros_to_add: 0\n",
      "Iteração 208\n",
      "Zeros_to_add: 1200\n",
      "Iteração 209\n",
      "Zeros_to_add: 600\n",
      "Iteração 210\n",
      "Zeros_to_add: 0\n",
      "Iteração 211\n",
      "Zeros_to_add: 2100\n",
      "Iteração 212\n",
      "Zeros_to_add: 300\n",
      "Iteração 213\n",
      "Zeros_to_add: 300\n",
      "Iteração 214\n",
      "Zeros_to_add: 300\n",
      "Iteração 215\n",
      "Zeros_to_add: 0\n",
      "Iteração 216\n",
      "Zeros_to_add: 0\n",
      "Iteração 217\n",
      "Zeros_to_add: 0\n",
      "Iteração 218\n",
      "Zeros_to_add: 300\n",
      "Iteração 219\n",
      "Zeros_to_add: 0\n",
      "Iteração 220\n",
      "Zeros_to_add: 0\n",
      "Iteração 221\n",
      "Zeros_to_add: 0\n",
      "Iteração 222\n",
      "Zeros_to_add: 2100\n",
      "Iteração 223\n",
      "Zeros_to_add: 0\n",
      "Iteração 224\n",
      "Zeros_to_add: 300\n",
      "Iteração 225\n",
      "Zeros_to_add: 1200\n",
      "Iteração 226\n",
      "Zeros_to_add: 300\n",
      "Iteração 227\n",
      "Zeros_to_add: 0\n",
      "Iteração 228\n",
      "Zeros_to_add: 600\n",
      "Iteração 229\n",
      "Zeros_to_add: 2100\n",
      "Iteração 230\n",
      "Zeros_to_add: 1200\n",
      "Iteração 231\n",
      "Zeros_to_add: 0\n",
      "Iteração 232\n",
      "Zeros_to_add: 0\n",
      "Iteração 233\n",
      "Zeros_to_add: 900\n",
      "Iteração 234\n",
      "Zeros_to_add: 1800\n",
      "Iteração 235\n",
      "Zeros_to_add: 300\n",
      "Iteração 236\n",
      "Zeros_to_add: 0\n",
      "Iteração 237\n",
      "Zeros_to_add: 2700\n",
      "Iteração 238\n",
      "Zeros_to_add: 300\n",
      "Iteração 239\n",
      "Zeros_to_add: 0\n",
      "Iteração 240\n",
      "Zeros_to_add: 1500\n",
      "Iteração 241\n",
      "Zeros_to_add: 1200\n",
      "Iteração 242\n",
      "Zeros_to_add: 2400\n",
      "Iteração 243\n",
      "Zeros_to_add: 0\n",
      "Iteração 244\n",
      "Zeros_to_add: 0\n",
      "Iteração 245\n",
      "Zeros_to_add: 300\n",
      "Iteração 246\n",
      "Zeros_to_add: 300\n",
      "Iteração 247\n",
      "Zeros_to_add: 300\n",
      "Iteração 248\n",
      "Zeros_to_add: 2100\n",
      "Iteração 249\n",
      "Zeros_to_add: 0\n",
      "Iteração 250\n",
      "Zeros_to_add: 300\n",
      "Iteração 251\n",
      "Zeros_to_add: 1200\n",
      "Iteração 252\n",
      "Zeros_to_add: 300\n",
      "Iteração 253\n",
      "Zeros_to_add: 1200\n",
      "Iteração 254\n",
      "Zeros_to_add: 1800\n",
      "Iteração 255\n",
      "Zeros_to_add: 0\n",
      "Iteração 256\n",
      "Zeros_to_add: 1800\n",
      "Iteração 257\n",
      "Zeros_to_add: 900\n",
      "Iteração 258\n",
      "Zeros_to_add: 1800\n",
      "Iteração 259\n",
      "Zeros_to_add: 0\n",
      "Iteração 260\n",
      "Zeros_to_add: 1200\n",
      "Iteração 261\n",
      "Zeros_to_add: 300\n",
      "Iteração 262\n",
      "Zeros_to_add: 300\n",
      "Iteração 263\n",
      "Zeros_to_add: 0\n",
      "Iteração 264\n",
      "Zeros_to_add: 0\n",
      "Iteração 265\n",
      "Zeros_to_add: 0\n",
      "Iteração 266\n",
      "Zeros_to_add: 1200\n",
      "Iteração 267\n",
      "Zeros_to_add: 0\n",
      "Iteração 268\n",
      "Zeros_to_add: 2700\n",
      "Iteração 269\n",
      "Zeros_to_add: 300\n",
      "Iteração 270\n",
      "Zeros_to_add: 300\n",
      "Iteração 271\n",
      "Zeros_to_add: 300\n",
      "Iteração 272\n",
      "Zeros_to_add: 0\n",
      "Iteração 273\n",
      "Zeros_to_add: 2700\n",
      "Iteração 274\n",
      "Zeros_to_add: 300\n",
      "Iteração 275\n",
      "Zeros_to_add: 300\n",
      "Iteração 276\n",
      "Zeros_to_add: 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteração 277\n",
      "Zeros_to_add: 1200\n",
      "Iteração 278\n",
      "Zeros_to_add: 0\n",
      "Iteração 279\n",
      "Zeros_to_add: 1500\n",
      "Iteração 280\n",
      "Zeros_to_add: 1200\n",
      "Iteração 281\n",
      "Zeros_to_add: 300\n",
      "Iteração 282\n",
      "Zeros_to_add: 300\n",
      "Iteração 283\n",
      "Zeros_to_add: 300\n",
      "Iteração 284\n",
      "Zeros_to_add: 0\n",
      "Iteração 285\n",
      "Zeros_to_add: 300\n",
      "Iteração 286\n",
      "Zeros_to_add: 300\n",
      "Iteração 287\n",
      "Zeros_to_add: 1200\n",
      "Iteração 288\n",
      "Zeros_to_add: 0\n",
      "Iteração 289\n",
      "Zeros_to_add: 300\n",
      "Iteração 290\n",
      "Zeros_to_add: 0\n",
      "Iteração 291\n",
      "Zeros_to_add: 1800\n",
      "Iteração 292\n",
      "Zeros_to_add: 0\n",
      "Iteração 293\n",
      "Zeros_to_add: 300\n",
      "Iteração 294\n",
      "Zeros_to_add: 600\n",
      "Iteração 295\n",
      "Zeros_to_add: 0\n",
      "Iteração 296\n",
      "Zeros_to_add: 1200\n",
      "Iteração 297\n",
      "Zeros_to_add: 900\n",
      "Iteração 298\n",
      "Zeros_to_add: 1200\n",
      "Iteração 299\n",
      "Zeros_to_add: 600\n",
      "Iteração 300\n",
      "Zeros_to_add: 0\n",
      "Iteração 301\n",
      "Zeros_to_add: 300\n",
      "Iteração 302\n",
      "Zeros_to_add: 1500\n",
      "Iteração 303\n",
      "Zeros_to_add: 3000\n",
      "Iteração 304\n",
      "Zeros_to_add: 300\n",
      "Iteração 305\n",
      "Zeros_to_add: 1200\n",
      "Iteração 306\n",
      "Zeros_to_add: 600\n",
      "Iteração 307\n",
      "Zeros_to_add: 0\n",
      "Iteração 308\n",
      "Zeros_to_add: 2700\n",
      "Iteração 309\n",
      "Zeros_to_add: 300\n",
      "Iteração 310\n",
      "Zeros_to_add: 600\n",
      "Iteração 311\n",
      "Zeros_to_add: 0\n",
      "Iteração 312\n",
      "Zeros_to_add: 0\n",
      "Iteração 313\n",
      "Zeros_to_add: 1200\n",
      "Iteração 314\n",
      "Zeros_to_add: 0\n",
      "Iteração 315\n",
      "Zeros_to_add: 1800\n",
      "Iteração 316\n",
      "Zeros_to_add: 0\n",
      "Iteração 317\n",
      "Zeros_to_add: 0\n",
      "Iteração 318\n",
      "Zeros_to_add: 0\n",
      "Iteração 319\n",
      "Zeros_to_add: 0\n",
      "Iteração 320\n",
      "Zeros_to_add: 1200\n",
      "Iteração 321\n",
      "Zeros_to_add: 300\n",
      "Iteração 322\n",
      "Zeros_to_add: 0\n",
      "Iteração 323\n",
      "Zeros_to_add: 300\n",
      "Iteração 324\n",
      "Zeros_to_add: 0\n",
      "Iteração 325\n",
      "Zeros_to_add: 1500\n",
      "Iteração 326\n",
      "Zeros_to_add: 1200\n",
      "Iteração 327\n",
      "Zeros_to_add: 0\n",
      "Iteração 328\n",
      "Zeros_to_add: 0\n",
      "Iteração 329\n",
      "Zeros_to_add: 300\n",
      "Iteração 330\n",
      "Zeros_to_add: 900\n",
      "Iteração 331\n",
      "Zeros_to_add: 2100\n",
      "Iteração 332\n",
      "Zeros_to_add: 900\n",
      "Iteração 333\n",
      "Zeros_to_add: 300\n",
      "Iteração 334\n",
      "Zeros_to_add: 300\n",
      "Iteração 335\n",
      "Zeros_to_add: 0\n",
      "Iteração 336\n",
      "Zeros_to_add: 0\n",
      "Iteração 337\n",
      "Zeros_to_add: 2700\n",
      "Iteração 338\n",
      "Zeros_to_add: 0\n",
      "Iteração 339\n",
      "Zeros_to_add: 0\n",
      "Iteração 340\n",
      "Zeros_to_add: 0\n",
      "Iteração 341\n",
      "Zeros_to_add: 3000\n",
      "Iteração 342\n",
      "Zeros_to_add: 300\n",
      "Iteração 343\n",
      "Zeros_to_add: 0\n",
      "Iteração 344\n",
      "Zeros_to_add: 2700\n",
      "Iteração 345\n",
      "Zeros_to_add: 0\n",
      "Iteração 346\n",
      "Zeros_to_add: 300\n",
      "Iteração 347\n",
      "Zeros_to_add: 300\n",
      "Iteração 348\n",
      "Zeros_to_add: 600\n",
      "Iteração 349\n",
      "Zeros_to_add: 0\n",
      "Iteração 350\n",
      "Zeros_to_add: 300\n",
      "Iteração 351\n",
      "Zeros_to_add: 0\n",
      "Iteração 352\n",
      "Zeros_to_add: 1500\n",
      "Iteração 353\n",
      "Zeros_to_add: 900\n",
      "Iteração 354\n",
      "Zeros_to_add: 0\n",
      "Iteração 355\n",
      "Zeros_to_add: 2700\n",
      "Iteração 356\n",
      "Zeros_to_add: 1800\n",
      "Iteração 357\n",
      "Zeros_to_add: 3000\n",
      "Iteração 358\n",
      "Zeros_to_add: 0\n",
      "Iteração 359\n",
      "Zeros_to_add: 1800\n",
      "Iteração 360\n",
      "Zeros_to_add: 0\n",
      "Iteração 361\n",
      "Zeros_to_add: 2400\n",
      "Iteração 362\n",
      "Zeros_to_add: 0\n",
      "Iteração 363\n",
      "Zeros_to_add: 300\n",
      "Iteração 364\n",
      "Zeros_to_add: 1200\n",
      "Iteração 365\n",
      "Zeros_to_add: 300\n",
      "Iteração 366\n",
      "Zeros_to_add: 300\n",
      "Iteração 367\n",
      "Zeros_to_add: 0\n",
      "Iteração 368\n",
      "Zeros_to_add: 0\n",
      "Iteração 369\n",
      "Zeros_to_add: 300\n",
      "Iteração 370\n",
      "Zeros_to_add: 0\n",
      "Iteração 371\n",
      "Zeros_to_add: 600\n",
      "Iteração 372\n",
      "Zeros_to_add: 1200\n",
      "Iteração 373\n",
      "Zeros_to_add: 1500\n",
      "Iteração 374\n",
      "Zeros_to_add: 1200\n",
      "Iteração 375\n",
      "Zeros_to_add: 2700\n",
      "Iteração 376\n",
      "Zeros_to_add: 900\n",
      "Iteração 377\n",
      "Zeros_to_add: 900\n",
      "Iteração 378\n",
      "Zeros_to_add: 1200\n",
      "Iteração 379\n",
      "Zeros_to_add: 300\n",
      "Iteração 380\n",
      "Zeros_to_add: 1800\n",
      "Iteração 381\n",
      "Zeros_to_add: 0\n",
      "Iteração 382\n",
      "Zeros_to_add: 1200\n",
      "Iteração 383\n",
      "Zeros_to_add: 1200\n",
      "Iteração 384\n",
      "Zeros_to_add: 1500\n",
      "Iteração 385\n",
      "Zeros_to_add: 2700\n",
      "Iteração 386\n",
      "Zeros_to_add: 300\n",
      "Iteração 387\n",
      "Zeros_to_add: 0\n",
      "Iteração 388\n",
      "Zeros_to_add: 0\n",
      "Iteração 389\n",
      "Zeros_to_add: 300\n",
      "Iteração 390\n",
      "Zeros_to_add: 0\n",
      "Iteração 391\n",
      "Zeros_to_add: 0\n",
      "Iteração 392\n",
      "Zeros_to_add: 2700\n",
      "Iteração 393\n",
      "Zeros_to_add: 1800\n",
      "Iteração 394\n",
      "Zeros_to_add: 2100\n",
      "Iteração 395\n",
      "Zeros_to_add: 0\n",
      "Iteração 396\n",
      "Zeros_to_add: 0\n",
      "Iteração 397\n",
      "Zeros_to_add: 0\n",
      "Iteração 398\n",
      "Zeros_to_add: 0\n",
      "Iteração 399\n",
      "Zeros_to_add: 0\n",
      "Iteração 400\n",
      "Zeros_to_add: 2100\n",
      "Iteração 401\n",
      "Zeros_to_add: 0\n",
      "Iteração 402\n",
      "Zeros_to_add: 0\n",
      "Iteração 403\n",
      "Zeros_to_add: 1200\n",
      "Iteração 404\n",
      "Zeros_to_add: 1200\n",
      "Iteração 405\n",
      "Zeros_to_add: 3000\n",
      "Iteração 406\n",
      "Zeros_to_add: 1200\n",
      "Iteração 407\n",
      "Zeros_to_add: 300\n",
      "Iteração 408\n",
      "Zeros_to_add: 1200\n",
      "Iteração 409\n",
      "Zeros_to_add: 0\n",
      "Iteração 410\n",
      "Zeros_to_add: 1500\n",
      "Iteração 411\n",
      "Zeros_to_add: 0\n",
      "Iteração 412\n",
      "Zeros_to_add: 600\n",
      "Iteração 413\n",
      "Zeros_to_add: 300\n",
      "Iteração 414\n",
      "Zeros_to_add: 0\n",
      "Iteração 415\n",
      "Zeros_to_add: 1500\n",
      "Iteração 416\n",
      "Zeros_to_add: 300\n",
      "Iteração 417\n",
      "Zeros_to_add: 1800\n",
      "Iteração 418\n",
      "Zeros_to_add: 300\n",
      "Iteração 419\n",
      "Zeros_to_add: 900\n",
      "Iteração 420\n",
      "Zeros_to_add: 300\n",
      "Iteração 421\n",
      "Zeros_to_add: 0\n",
      "Iteração 422\n",
      "Zeros_to_add: 0\n",
      "Iteração 423\n",
      "Zeros_to_add: 0\n",
      "Iteração 424\n",
      "Zeros_to_add: 900\n",
      "Iteração 425\n",
      "Zeros_to_add: 0\n",
      "Iteração 426\n",
      "Zeros_to_add: 0\n",
      "Iteração 427\n",
      "Zeros_to_add: 300\n",
      "Iteração 428\n",
      "Zeros_to_add: 1800\n",
      "Iteração 429\n",
      "Zeros_to_add: 0\n",
      "Iteração 430\n",
      "Zeros_to_add: 1200\n",
      "Iteração 431\n",
      "Zeros_to_add: 0\n",
      "Iteração 432\n",
      "Zeros_to_add: 0\n",
      "Iteração 433\n",
      "Zeros_to_add: 300\n",
      "Iteração 434\n",
      "Zeros_to_add: 1500\n",
      "Iteração 435\n",
      "Zeros_to_add: 900\n",
      "Iteração 436\n",
      "Zeros_to_add: 0\n",
      "Iteração 437\n",
      "Zeros_to_add: 2100\n",
      "Iteração 438\n",
      "Zeros_to_add: 600\n",
      "Iteração 439\n",
      "Zeros_to_add: 0\n",
      "Iteração 440\n",
      "Zeros_to_add: 0\n",
      "Iteração 441\n",
      "Zeros_to_add: 900\n",
      "Iteração 442\n",
      "Zeros_to_add: 0\n",
      "Iteração 443\n",
      "Zeros_to_add: 1500\n",
      "Iteração 444\n",
      "Zeros_to_add: 1200\n",
      "Iteração 445\n",
      "Zeros_to_add: 2700\n",
      "Iteração 446\n",
      "Zeros_to_add: 2700\n",
      "Iteração 447\n",
      "Zeros_to_add: 2700\n",
      "Iteração 448\n",
      "Zeros_to_add: 0\n",
      "Iteração 449\n",
      "Zeros_to_add: 1500\n",
      "Iteração 450\n",
      "Zeros_to_add: 300\n",
      "Iteração 451\n",
      "Zeros_to_add: 300\n",
      "Iteração 452\n",
      "Zeros_to_add: 300\n",
      "Iteração 453\n",
      "Zeros_to_add: 3000\n",
      "Iteração 454\n",
      "Zeros_to_add: 600\n",
      "Iteração 455\n",
      "Zeros_to_add: 0\n",
      "Iteração 456\n",
      "Zeros_to_add: 0\n",
      "Iteração 457\n",
      "Zeros_to_add: 300\n",
      "Iteração 458\n",
      "Zeros_to_add: 0\n",
      "Iteração 459\n",
      "Zeros_to_add: 1200\n",
      "Iteração 460\n",
      "Zeros_to_add: 1500\n",
      "Iteração 461\n",
      "Zeros_to_add: 0\n",
      "Iteração 462\n",
      "Zeros_to_add: 1800\n",
      "Iteração 463\n",
      "Zeros_to_add: 300\n",
      "Iteração 464\n",
      "Zeros_to_add: 0\n",
      "Iteração 465\n",
      "Zeros_to_add: 300\n",
      "Iteração 466\n",
      "Zeros_to_add: 300\n",
      "Iteração 467\n",
      "Zeros_to_add: 1200\n",
      "Iteração 468\n",
      "Zeros_to_add: 300\n",
      "Iteração 469\n",
      "Zeros_to_add: 0\n",
      "Iteração 470\n",
      "Zeros_to_add: 1200\n",
      "Iteração 471\n",
      "Zeros_to_add: 300\n",
      "Iteração 472\n",
      "Zeros_to_add: 300\n",
      "Iteração 473\n",
      "Zeros_to_add: 0\n",
      "Iteração 474\n",
      "Zeros_to_add: 300\n",
      "Iteração 475\n",
      "Zeros_to_add: 0\n",
      "Iteração 476\n",
      "Zeros_to_add: 0\n",
      "Iteração 477\n",
      "Zeros_to_add: 0\n",
      "Iteração 478\n",
      "Zeros_to_add: 300\n",
      "Iteração 479\n",
      "Zeros_to_add: 0\n",
      "Iteração 480\n",
      "Zeros_to_add: 1200\n",
      "Iteração 481\n",
      "Zeros_to_add: 300\n",
      "Iteração 482\n",
      "Zeros_to_add: 300\n",
      "Iteração 483\n",
      "Zeros_to_add: 0\n",
      "Iteração 484\n",
      "Zeros_to_add: 1200\n",
      "Iteração 485\n",
      "Zeros_to_add: 300\n",
      "Iteração 486\n",
      "Zeros_to_add: 300\n",
      "Iteração 487\n",
      "Zeros_to_add: 0\n",
      "Iteração 488\n",
      "Zeros_to_add: 0\n",
      "Iteração 489\n",
      "Zeros_to_add: 0\n",
      "Iteração 490\n",
      "Zeros_to_add: 0\n",
      "Iteração 491\n",
      "Zeros_to_add: 0\n",
      "Iteração 492\n",
      "Zeros_to_add: 1200\n",
      "Iteração 493\n",
      "Zeros_to_add: 0\n",
      "Iteração 494\n",
      "Zeros_to_add: 300\n",
      "Iteração 495\n",
      "Zeros_to_add: 0\n",
      "Iteração 496\n",
      "Zeros_to_add: 0\n",
      "Iteração 497\n",
      "Zeros_to_add: 600\n",
      "Iteração 498\n",
      "Zeros_to_add: 0\n",
      "Iteração 499\n",
      "Zeros_to_add: 1500\n",
      "Iteração 500\n",
      "Zeros_to_add: 600\n",
      "Iteração 501\n",
      "Zeros_to_add: 300\n",
      "Iteração 502\n",
      "Zeros_to_add: 1800\n",
      "Iteração 503\n",
      "Zeros_to_add: 900\n",
      "Iteração 504\n",
      "Zeros_to_add: 0\n",
      "Iteração 505\n",
      "Zeros_to_add: 300\n",
      "Iteração 506\n",
      "Zeros_to_add: 0\n",
      "Iteração 507\n",
      "Zeros_to_add: 1500\n",
      "Iteração 508\n",
      "Zeros_to_add: 0\n",
      "Iteração 509\n",
      "Zeros_to_add: 300\n",
      "Iteração 510\n",
      "Zeros_to_add: 2700\n",
      "Iteração 511\n",
      "Zeros_to_add: 2700\n",
      "Iteração 512\n",
      "Zeros_to_add: 2700\n",
      "Iteração 513\n",
      "Zeros_to_add: 1200\n",
      "Iteração 514\n",
      "Zeros_to_add: 300\n",
      "Iteração 515\n",
      "Zeros_to_add: 0\n",
      "Iteração 516\n",
      "Zeros_to_add: 1200\n",
      "Iteração 517\n",
      "Zeros_to_add: 900\n",
      "Iteração 518\n",
      "Zeros_to_add: 0\n",
      "Iteração 519\n",
      "Zeros_to_add: 0\n",
      "Iteração 520\n",
      "Zeros_to_add: 2700\n",
      "Iteração 521\n",
      "Zeros_to_add: 0\n",
      "Iteração 522\n",
      "Zeros_to_add: 1200\n",
      "Iteração 523\n",
      "Zeros_to_add: 300\n",
      "Iteração 524\n",
      "Zeros_to_add: 0\n",
      "Iteração 525\n",
      "Zeros_to_add: 1500\n",
      "Iteração 526\n",
      "Zeros_to_add: 0\n",
      "Iteração 527\n",
      "Zeros_to_add: 1200\n",
      "Iteração 528\n",
      "Zeros_to_add: 0\n",
      "Iteração 529\n",
      "Zeros_to_add: 0\n",
      "Iteração 530\n",
      "Zeros_to_add: 1200\n",
      "Iteração 531\n",
      "Zeros_to_add: 0\n",
      "Iteração 532\n",
      "Zeros_to_add: 300\n",
      "Iteração 533\n",
      "Zeros_to_add: 600\n",
      "Iteração 534\n",
      "Zeros_to_add: 0\n",
      "Iteração 535\n",
      "Zeros_to_add: 0\n",
      "Iteração 536\n",
      "Zeros_to_add: 900\n",
      "Iteração 537\n",
      "Zeros_to_add: 1800\n",
      "Iteração 538\n",
      "Zeros_to_add: 600\n",
      "Iteração 539\n",
      "Zeros_to_add: 300\n",
      "Iteração 540\n",
      "Zeros_to_add: 1500\n",
      "Iteração 541\n",
      "Zeros_to_add: 300\n",
      "Iteração 542\n",
      "Zeros_to_add: 300\n",
      "Iteração 543\n",
      "Zeros_to_add: 300\n",
      "Iteração 544\n",
      "Zeros_to_add: 0\n",
      "Iteração 545\n",
      "Zeros_to_add: 0\n",
      "Iteração 546\n",
      "Zeros_to_add: 0\n",
      "Iteração 547\n",
      "Zeros_to_add: 300\n",
      "Iteração 548\n",
      "Zeros_to_add: 1200\n",
      "Iteração 549\n",
      "Zeros_to_add: 300\n",
      "Iteração 550\n",
      "Zeros_to_add: 1200\n",
      "Iteração 551\n",
      "Zeros_to_add: 900\n",
      "Iteração 552\n",
      "Zeros_to_add: 0\n",
      "Iteração 553\n",
      "Zeros_to_add: 900\n",
      "Iteração 554\n",
      "Zeros_to_add: 1500\n",
      "Iteração 555\n",
      "Zeros_to_add: 1800\n",
      "Iteração 556\n",
      "Zeros_to_add: 900\n",
      "Iteração 557\n",
      "Zeros_to_add: 300\n",
      "Iteração 558\n",
      "Zeros_to_add: 0\n",
      "Iteração 559\n",
      "Zeros_to_add: 0\n",
      "Iteração 560\n",
      "Zeros_to_add: 1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteração 561\n",
      "Zeros_to_add: 0\n",
      "Iteração 562\n",
      "Zeros_to_add: 0\n",
      "Iteração 563\n",
      "Zeros_to_add: 300\n",
      "Iteração 564\n",
      "Zeros_to_add: 0\n",
      "Iteração 565\n",
      "Zeros_to_add: 300\n",
      "Iteração 566\n",
      "Zeros_to_add: 0\n",
      "Iteração 567\n",
      "Zeros_to_add: 0\n",
      "Iteração 568\n",
      "Zeros_to_add: 0\n",
      "Iteração 569\n",
      "Zeros_to_add: 0\n",
      "Iteração 570\n",
      "Zeros_to_add: 900\n",
      "Iteração 571\n",
      "Zeros_to_add: 300\n",
      "Iteração 572\n",
      "Zeros_to_add: 0\n",
      "Iteração 573\n",
      "Zeros_to_add: 0\n",
      "Iteração 574\n",
      "Zeros_to_add: 1200\n",
      "Iteração 575\n",
      "Zeros_to_add: 0\n",
      "Iteração 576\n",
      "Zeros_to_add: 600\n",
      "Iteração 577\n",
      "Zeros_to_add: 2700\n",
      "Iteração 578\n",
      "Zeros_to_add: 2700\n",
      "Iteração 579\n",
      "Zeros_to_add: 900\n",
      "Iteração 580\n",
      "Zeros_to_add: 900\n",
      "Iteração 581\n",
      "Zeros_to_add: 0\n",
      "Iteração 582\n",
      "Zeros_to_add: 0\n",
      "Iteração 583\n",
      "Zeros_to_add: 1500\n",
      "Iteração 584\n",
      "Zeros_to_add: 0\n",
      "Iteração 585\n",
      "Zeros_to_add: 900\n",
      "Iteração 586\n",
      "Zeros_to_add: 300\n",
      "Iteração 587\n",
      "Zeros_to_add: 0\n",
      "Iteração 588\n",
      "Zeros_to_add: 1800\n",
      "Iteração 589\n",
      "Zeros_to_add: 2700\n",
      "Iteração 590\n",
      "Zeros_to_add: 2700\n",
      "Iteração 591\n",
      "Zeros_to_add: 0\n",
      "Iteração 592\n",
      "Zeros_to_add: 300\n",
      "Iteração 593\n",
      "Zeros_to_add: 0\n",
      "Iteração 594\n",
      "Zeros_to_add: 2700\n",
      "Iteração 595\n",
      "Zeros_to_add: 1200\n",
      "Iteração 596\n",
      "Zeros_to_add: 900\n",
      "Iteração 597\n",
      "Zeros_to_add: 600\n",
      "Iteração 598\n",
      "Zeros_to_add: 900\n",
      "Iteração 599\n",
      "Zeros_to_add: 300\n",
      "Iteração 600\n",
      "Zeros_to_add: 1800\n",
      "Iteração 601\n",
      "Zeros_to_add: 0\n",
      "Iteração 602\n",
      "Zeros_to_add: 3000\n",
      "Iteração 603\n",
      "Zeros_to_add: 1800\n",
      "Iteração 604\n",
      "Zeros_to_add: 0\n",
      "Iteração 605\n",
      "Zeros_to_add: 0\n",
      "Iteração 606\n",
      "Zeros_to_add: 300\n",
      "Iteração 607\n",
      "Zeros_to_add: 300\n",
      "Iteração 608\n",
      "Zeros_to_add: 0\n",
      "Iteração 609\n",
      "Zeros_to_add: 300\n",
      "Iteração 610\n",
      "Zeros_to_add: 0\n",
      "Iteração 611\n",
      "Zeros_to_add: 2700\n",
      "Iteração 612\n",
      "Zeros_to_add: 300\n",
      "Iteração 613\n",
      "Zeros_to_add: 0\n",
      "Iteração 614\n",
      "Zeros_to_add: 0\n",
      "Iteração 615\n",
      "Zeros_to_add: 1200\n",
      "Iteração 616\n",
      "Zeros_to_add: 600\n",
      "Iteração 617\n",
      "Zeros_to_add: 0\n",
      "Iteração 618\n",
      "Zeros_to_add: 300\n",
      "Iteração 619\n",
      "Zeros_to_add: 0\n",
      "Iteração 620\n",
      "Zeros_to_add: 0\n",
      "Iteração 621\n",
      "Zeros_to_add: 1800\n",
      "Iteração 622\n",
      "Zeros_to_add: 0\n",
      "Iteração 623\n",
      "Zeros_to_add: 0\n",
      "Iteração 624\n",
      "Zeros_to_add: 0\n",
      "Iteração 625\n",
      "Zeros_to_add: 0\n",
      "Iteração 626\n",
      "Zeros_to_add: 0\n",
      "Iteração 627\n",
      "Zeros_to_add: 600\n",
      "Iteração 628\n",
      "Zeros_to_add: 1200\n",
      "Iteração 629\n",
      "Zeros_to_add: 1800\n",
      "Iteração 630\n",
      "Zeros_to_add: 0\n",
      "Iteração 631\n",
      "Zeros_to_add: 1200\n",
      "Iteração 632\n",
      "Zeros_to_add: 0\n",
      "Iteração 633\n",
      "Zeros_to_add: 600\n",
      "Iteração 634\n",
      "Zeros_to_add: 0\n",
      "Iteração 635\n",
      "Zeros_to_add: 2700\n",
      "Iteração 636\n",
      "Zeros_to_add: 300\n",
      "Iteração 637\n",
      "Zeros_to_add: 300\n",
      "Iteração 638\n",
      "Zeros_to_add: 300\n",
      "Iteração 639\n",
      "Zeros_to_add: 0\n",
      "Iteração 640\n",
      "Zeros_to_add: 1800\n",
      "Iteração 641\n",
      "Zeros_to_add: 0\n",
      "Iteração 642\n",
      "Zeros_to_add: 0\n",
      "Iteração 643\n",
      "Zeros_to_add: 0\n",
      "Iteração 644\n",
      "Zeros_to_add: 300\n",
      "Iteração 645\n",
      "Zeros_to_add: 0\n",
      "Iteração 646\n",
      "Zeros_to_add: 1500\n",
      "Iteração 647\n",
      "Zeros_to_add: 1800\n",
      "Iteração 648\n",
      "Zeros_to_add: 1500\n",
      "Iteração 649\n",
      "Zeros_to_add: 0\n",
      "Iteração 650\n",
      "Zeros_to_add: 0\n",
      "Iteração 651\n",
      "Zeros_to_add: 0\n",
      "Iteração 652\n",
      "Zeros_to_add: 300\n",
      "Iteração 653\n",
      "Zeros_to_add: 0\n",
      "Iteração 654\n",
      "Zeros_to_add: 300\n",
      "Iteração 655\n",
      "Zeros_to_add: 1500\n",
      "Iteração 656\n",
      "Zeros_to_add: 3000\n",
      "Iteração 657\n",
      "Zeros_to_add: 0\n",
      "Iteração 658\n",
      "Zeros_to_add: 300\n",
      "Iteração 659\n",
      "Zeros_to_add: 0\n",
      "Iteração 660\n",
      "Zeros_to_add: 300\n",
      "Iteração 661\n",
      "Zeros_to_add: 0\n",
      "Iteração 662\n",
      "Zeros_to_add: 1200\n",
      "Iteração 663\n",
      "Zeros_to_add: 1200\n",
      "Iteração 664\n",
      "Zeros_to_add: 300\n",
      "Iteração 665\n",
      "Zeros_to_add: 0\n",
      "Iteração 666\n",
      "Zeros_to_add: 0\n",
      "Iteração 667\n",
      "Zeros_to_add: 300\n",
      "Iteração 668\n",
      "Zeros_to_add: 0\n",
      "Iteração 669\n",
      "Zeros_to_add: 900\n",
      "Iteração 670\n",
      "Zeros_to_add: 0\n",
      "Iteração 671\n",
      "Zeros_to_add: 1500\n",
      "Iteração 672\n",
      "Zeros_to_add: 300\n",
      "Iteração 673\n",
      "Zeros_to_add: 300\n",
      "Iteração 674\n",
      "Zeros_to_add: 2700\n",
      "Iteração 675\n",
      "Zeros_to_add: 0\n",
      "Iteração 676\n",
      "Zeros_to_add: 0\n",
      "Iteração 677\n",
      "Zeros_to_add: 1800\n",
      "Iteração 678\n",
      "Zeros_to_add: 1200\n",
      "Iteração 679\n",
      "Zeros_to_add: 1200\n",
      "Iteração 680\n",
      "Zeros_to_add: 0\n",
      "Iteração 681\n",
      "Zeros_to_add: 600\n",
      "Iteração 682\n",
      "Zeros_to_add: 0\n",
      "Iteração 683\n",
      "Zeros_to_add: 300\n",
      "Iteração 684\n",
      "Zeros_to_add: 0\n",
      "Iteração 685\n",
      "Zeros_to_add: 300\n",
      "Iteração 686\n",
      "Zeros_to_add: 900\n",
      "Iteração 687\n",
      "Zeros_to_add: 1200\n",
      "Iteração 688\n",
      "Zeros_to_add: 2100\n",
      "Iteração 689\n",
      "Zeros_to_add: 0\n",
      "Iteração 690\n",
      "Zeros_to_add: 0\n",
      "Iteração 691\n",
      "Zeros_to_add: 0\n",
      "Iteração 692\n",
      "Zeros_to_add: 300\n",
      "Iteração 693\n",
      "Zeros_to_add: 0\n",
      "Iteração 694\n",
      "Zeros_to_add: 1800\n",
      "Iteração 695\n",
      "Zeros_to_add: 1200\n",
      "Iteração 696\n",
      "Zeros_to_add: 1500\n",
      "Iteração 697\n",
      "Zeros_to_add: 300\n",
      "Iteração 698\n",
      "Zeros_to_add: 0\n",
      "Iteração 699\n",
      "Zeros_to_add: 0\n",
      "Iteração 700\n",
      "Zeros_to_add: 300\n",
      "Iteração 701\n",
      "Zeros_to_add: 0\n",
      "Iteração 702\n",
      "Zeros_to_add: 1200\n",
      "Iteração 703\n",
      "Zeros_to_add: 0\n",
      "Iteração 704\n",
      "Zeros_to_add: 0\n",
      "Iteração 705\n",
      "Zeros_to_add: 1800\n",
      "Iteração 706\n",
      "Zeros_to_add: 0\n",
      "Iteração 707\n",
      "Zeros_to_add: 900\n",
      "Iteração 708\n",
      "Zeros_to_add: 0\n",
      "Iteração 709\n",
      "Zeros_to_add: 900\n",
      "Iteração 710\n",
      "Zeros_to_add: 300\n",
      "Iteração 711\n",
      "Zeros_to_add: 0\n",
      "Iteração 712\n",
      "Zeros_to_add: 0\n",
      "Iteração 713\n",
      "Zeros_to_add: 300\n",
      "Iteração 714\n",
      "Zeros_to_add: 0\n",
      "Iteração 715\n",
      "Zeros_to_add: 0\n",
      "Iteração 716\n",
      "Zeros_to_add: 2400\n",
      "Iteração 717\n",
      "Zeros_to_add: 900\n",
      "(717, 6000)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "array_length = 20 * 300\n",
    "embedding_featuresPT = pd.DataFrame()\n",
    "i = 0\n",
    "for document in textPT:\n",
    "    i = i + 1\n",
    "    # Saving the first 20 words of the document as a sequence\n",
    "    words = text_to_word_sequence(document)[0:20] \n",
    "    \n",
    "    # Retrieving the vector representation of each word and \n",
    "    # appending it to the feature vector \n",
    "    feature_vector = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            feature_vector = np.append(feature_vector, \n",
    "                                       np.array(embedsPT[word]))\n",
    "        except KeyError:\n",
    "            # In the event that a word is not included in our \n",
    "            # dictionary skip that word\n",
    "            pass\n",
    "    # If the text has less then 20 words, fill remaining vector with\n",
    "    # zeros\n",
    "    zeroes_to_add = array_length - len(feature_vector)\n",
    "    print('Iteração %d' %i)\n",
    "    print('Zeros_to_add: %d' %zeroes_to_add)\n",
    "    feature_vector = np.append(feature_vector, \n",
    "                               np.zeros(zeroes_to_add)\n",
    "                               ).reshape((1,-1))\n",
    "    \n",
    "    # Append the document feature vector to the feature table\n",
    "    embedding_featuresPT = embedding_featuresPT.append( \n",
    "                                     pd.DataFrame(feature_vector))\n",
    "print(embedding_featuresPT.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split em treino e teste dos conjutos carregados de embeddings\n",
    "Novamente, assim como ao carregar o modelo, aqui as variáveis foram sobrescritas conforme atualização do diferentes conjuntos de vetores pré-treinados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(573, 6000) (144, 6000)\n",
      "(144,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "emb_train, emb_test = train_test_split(embedding_featuresPT, test_size=0.2, random_state=123)\n",
    "\n",
    "print(emb_train.shape, emb_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost + Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_cls_emb = xgb.XGBClassifier(base_score=0.5, colsample_bylevel=1, objective='multi:softprob', colsample_bytree = 1, gamma=0, learning_rate = 0.1, max_delta_step=0,\n",
    "                max_depth = 3, min_child_weight=1, missing=None, alpha = 10, n_estimators = 100, nthread=-1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, subsample=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez instanciado o objeto XGBClassifier, o reutilizamos a cada novo modelo de embeddings carregado, rodando o método fit com as embeddings de treino do modelo vigente e guardando em uma variável única o retorno do método predict, usado nas embeddings de teste do método vigente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGBoost + Glove 300D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:59:23] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=-1, nthread=-1, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=42, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, seed=42, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_cls_emb.fit(emb_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_glove_xgb = xg_cls_emb.predict(emb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGBoost + Word2Vec SKIP-GRAM 300D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:39:15] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=-1, nthread=-1, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=42, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, seed=42, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_cls_emb.fit(emb_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_w2vskip300_xgb = xg_cls_emb.predict(emb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGBoost + FastText CBOW 300D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:30:58] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=-1, nthread=-1, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=42, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, seed=42, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_cls_emb.fit(emb_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_cbow300ft_xgb = xg_cls_emb.predict(emb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XGBoost + FastText SKIP-GRAM 300D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:18:35] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=-1, nthread=-1, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=42, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, seed=42, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_cls_emb.fit(emb_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_skip300ft_xgb = xg_cls_emb.predict(emb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM + Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM + Glove 300D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_emb_glove300 = LinearSVC(max_iter=40000)\n",
    "svm_model_emb_glove300.fit(emb_train, y_train)\n",
    "svm_pred_emb_glove300 = svm_model_emb_glove300.predict(emb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM + Word2Vec SKIP-GRAM 300D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_emb_w2vskip300 = LinearSVC(max_iter=10000)\n",
    "svm_model_emb_w2vskip300.fit(emb_train, y_train)\n",
    "svm_pred_emb_w2vskip300 = svm_model_emb_w2vskip300.predict(emb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM + FastText CBOW 300D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mstauffer/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "svm_model_emb_cbow300ft = LinearSVC(max_iter = 40000)\n",
    "svm_model_emb_cbow300ft.fit(emb_train, y_train)\n",
    "svm_pred_emb_cbow300ft = svm_model_emb_cbow300ft.predict(emb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM + FastText SKIP-GRAM 300D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_emb = LinearSVC(max_iter=10000)\n",
    "svm_model_emb.fit(emb_train, y_train)\n",
    "svm_prediction_emb = svm_model_emb.predict(emb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mstauffer/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mstauffer/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TFIDF + SVM</th>\n",
       "      <td>0.947996</td>\n",
       "      <td>0.951389</td>\n",
       "      <td>0.946878</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TFIDF + XGBoost</th>\n",
       "      <td>0.927313</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.926580</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emb FT Skip 300D + SVM</th>\n",
       "      <td>0.930072</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.930466</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emb FT CBOW 300D + SVM</th>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.891195</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emb W2V Skip 300D + SVM</th>\n",
       "      <td>0.936474</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.933651</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emb Glove 300D + SVM</th>\n",
       "      <td>0.912706</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.910056</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emb FT Skip 300D + XGBoost</th>\n",
       "      <td>0.895734</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.892506</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emb FT CBOW 300D + XGBoost</th>\n",
       "      <td>0.899561</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.894835</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emb W2V Skip 300D + XGBoost</th>\n",
       "      <td>0.926134</td>\n",
       "      <td>0.909722</td>\n",
       "      <td>0.911945</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emb Glove 300D + XGBoost</th>\n",
       "      <td>0.903890</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.891115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Precision    Recall  F1 score  support\n",
       "TFIDF + SVM                   0.947996  0.951389  0.946878      NaN\n",
       "TFIDF + XGBoost               0.927313  0.930556  0.926580      NaN\n",
       "Emb FT Skip 300D + SVM        0.930072  0.937500  0.930466      NaN\n",
       "Emb FT CBOW 300D + SVM        0.893617  0.895833  0.891195      NaN\n",
       "Emb W2V Skip 300D + SVM       0.936474  0.937500  0.933651      NaN\n",
       "Emb Glove 300D + SVM          0.912706  0.916667  0.910056      NaN\n",
       "Emb FT Skip 300D + XGBoost    0.895734  0.895833  0.892506      NaN\n",
       "Emb FT CBOW 300D + XGBoost    0.899561  0.902778  0.894835      NaN\n",
       "Emb W2V Skip 300D + XGBoost   0.926134  0.909722  0.911945      NaN\n",
       "Emb Glove 300D + XGBoost      0.903890  0.895833  0.891115      NaN"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsPT = pd.DataFrame(columns = ['Precision', 'Recall', 'F1 score', 'support']\n",
    "          )\n",
    "resultsPT.loc['TFIDF + SVM'] = precision_recall_fscore_support(\n",
    "          y_test, \n",
    "          #labelPT[train_cutoff + 1 : len(text)], \n",
    "          svm_predictionPT, \n",
    "          average = 'weighted'\n",
    "          )\n",
    "resultsPT.loc['TFIDF + XGBoost'] = precision_recall_fscore_support(\n",
    "          y_test, \n",
    "          preds, \n",
    "          average = 'weighted'\n",
    "          )\n",
    "resultsPT.loc['Emb FT Skip 300D + SVM'] = precision_recall_fscore_support(\n",
    "          y_test, \n",
    "          svm_prediction_emb, \n",
    "          average = 'weighted'\n",
    "          )\n",
    "resultsPT.loc['Emb FT CBOW 300D + SVM'] = precision_recall_fscore_support(\n",
    "          y_test, \n",
    "          svm_pred_emb_cbow300ft, \n",
    "          average = 'weighted'\n",
    "          )\n",
    "resultsPT.loc['Emb W2V Skip 300D + SVM'] = precision_recall_fscore_support(\n",
    "          y_test, \n",
    "          svm_pred_emb_w2vskip300, \n",
    "          average = 'weighted'\n",
    "          )\n",
    "resultsPT.loc['Emb Glove 300D + SVM'] = precision_recall_fscore_support(\n",
    "          y_test, \n",
    "          svm_pred_emb_glove300, \n",
    "          average = 'weighted'\n",
    "          )\n",
    "resultsPT.loc['Emb FT Skip 300D + XGBoost'] = precision_recall_fscore_support(\n",
    "          y_test, \n",
    "          preds_skip300ft_xgb, \n",
    "          average = 'weighted'\n",
    "          )\n",
    "resultsPT.loc['Emb FT CBOW 300D + XGBoost'] = precision_recall_fscore_support(\n",
    "          y_test, \n",
    "          preds_cbow300ft_xgb, \n",
    "          average = 'weighted'\n",
    "          )\n",
    "resultsPT.loc['Emb W2V Skip 300D + XGBoost'] = precision_recall_fscore_support(\n",
    "          y_test, \n",
    "          preds_w2vskip300_xgb, \n",
    "          average = 'weighted'\n",
    "          )\n",
    "resultsPT.loc['Emb Glove 300D + XGBoost'] = precision_recall_fscore_support(\n",
    "          y_test, \n",
    "          preds_glove_xgb, \n",
    "          average = 'weighted'\n",
    "          )\n",
    "\n",
    "resultsPT.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comentários finais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A combinação Glove 300D + SVM precisou de 40000 iterações para convergir. A combinação FastText CBOW 300D + SVM, com 40000 iterações, não convergiu.\n",
    "\n",
    "Os resultados permitem a elaboração de algumas hipóteses:\n",
    "- Para conjuntos pequenos de texto, o uso de XGBoost não necessariamente traz melhorias em relação ao baseline SVM.\n",
    "- O mesmo pode ser dito do uso de embeddings: a combinação que atingiu os melhores resultados, FastText Skip-Gram 300D + SVM, ainda assim não superou o baseline TFIDF + SVM.\n",
    "- O tempo de treinamento do baseline é menor do que em todas as outras combinações. Isso pesa ainda mais no trade-off: parece que para conjuntos pequenos de texto, o mais simples é o melhor.\n",
    "\n",
    "Evidentemente, para concluir quaiquer dessas hipóteses acima, seria necessário mais testes com mais conjuntos de dados de cunho semelhante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
